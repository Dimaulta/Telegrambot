## Политика модерации контента Neurfotobot

### Общие принципы
- Все входящие медиа и текстовые промпты проходят автоматическую модерацию до передачи во внешние AI-сервисы.
- Выявление запрещённых материалов приводит к немедленному прекращению обработки, удалению данных и блокировке пользователя.
- Команда фиксирует каждое срабатывание в журнале инцидентов и готова предоставить информацию компетентным органам.

### Проверка фотографий (Google Cloud Vision SafeSearch)
1. Получаем от пользователя до 10 изображений.
2. Отправляем каждое изображение в Google Cloud Vision API с включённым SafeSearch Detection.
3. Если любая из меток `adult`, `violence`, `racy`, `medical` имеет уровень `LIKELY` или `VERY_LIKELY`, запрос считается нарушением.
4. Нарушение → немедленно прекращаем обучение модели, удаляем исходные файлы из временного хранилища, очищаем кеш и результаты API.
5. Фиксируем инцидент в журнале: `user_id`, время, идентификатор изображения, ответ SafeSearch, предпринятые действия.
6. При подозрении на CSAM инициируем процедуру уведомления (см. шаблон ниже).

### Проверка текстовых промптов (Azure AI Content Safety)
1. Каждый промпт пользователя отправляется в API Azure AI Content Safety (Text) до генерации изображения.
2. Если категория `Sexual`, `Sexual Minors`, `Violence`, `Self-Harm`, `Hate` возвращается с уровнем `High` или выше установленного порога — промпт блокируется.
3. Пользователь получает уведомление об отказе; инцидент заносится в журнал.
4. При повторных нарушениях пользователь автоматически блокируется.

### Журнал инцидентов
- Формат записи: `timestamp`, `user_id`, тип проверки (image/text), исходный ресурс (file_id или hash), ответ модерации (категория, confidence), действие (удалено/заблокировано/сообщено).
- Журнал хранится в защищённом сегменте (доступ только у ответственных лиц). Срок хранения записей согласован с политикой безопасности проекта.

### Шаблон уведомления (внутренний)

```
Тема: [ИНЦИДЕНТ МОДЕРАЦИИ] Подозрение на запрещённый контент

Дата/время: {{timestamp}}
Пользователь: {{user_id}}
Тип проверки: {{image|text}}
Идентификатор ресурса: {{file_id|prompt_hash}}
Ответ модерации:
  - Сервис: {{Google SafeSearch|Azure Content Safety}}
  - Категория: {{category}}
  - Уровень уверенности: {{likelihood/confidence}}

Предпринятые действия:
- Удаление исходных данных: {{да/нет + детали}}
- Блокировка пользователя: {{да/нет}}
- Уведомление компетентных органов: {{да/нет + при необходимости ссылка на отчёт}}

Дополнительные заметки:
{{свободный текст}}

Ответственный: {{имя}}
```

### Предупреждение пользователей
- При первом взаимодействии бот отправляет уведомление, что все загруженные материалы и промпты проходят автоматическую модерацию.
- Пользователь соглашается с политикой, продолжая использование сервиса.

### Быстрая реакция
- Любое срабатывание SafeSearch или Azure Content Safety с высоким уровнем — повод для немедленного отключения пользователя от сервиса.
- По необходимости инициируем передачу данных в правоохранительные органы согласно законодательству и требованиям поставщиков API.

